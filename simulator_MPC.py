'''
File for simulation of the quadrotor in a given environment. This file is used for tracking:
    - A path generated by RRT_star
    - Converted into a trajectory by means of cubic spline interpolation or minimum snap
    - Tracked by means of a model-predictive controller (MPC)
'''

import numpy as np
from RRT_3D.RRT_star_plotter import RRT_star
from simulator_helpers import generate_env, plot_all, init_simulation, find_closest
from traj_optimization.cubic_spline import cubic_spline
from traj_optimization.mini_snap_optim import min_snap_optimizer_3d

if __name__ == "__main__":
    '''
    Some parameters for different performance/scenario settings
    '''
    ################################################################
    # some parameters
    obstacle = False # whether to have an local obstacle
    use_pre_saved_traj = False # whether to generate new trajectory using RRT* + trajectory smoothing
    dynamic_obstacle = False # whether to use dynamic obstacle
    traj_total_time = 25 # total time for the whole trajectory
    collision_avoidance_guarantee = True # whether to provide collision avoidance guarantee
    waypoint_navigation = False # whether to use waypoints navigation given by RRT* instead of trajectory given by min_snap
    min_snap = False

    if dynamic_obstacle:
        obstacle = True
    ###############################################################

    # Create the quadrotor class, controller and other initial values
    env, policy, t, time_step, total_SE, total_energy, penalty = init_simulation(mpc=True, traj_tracking=True, time_horizon = 40, obstacle=obstacle)
    #################################################################
    # Define the obstacles, plotting figure and axis and other scenario properties
    scenario = 4
    obstacles, fig, ax1, map_boundary, starts, ends = generate_env(scenario)
    #########################################################################
    # global path planning using RRT*
    x_start = starts[0]
    x_goal = ends[0]

    if not use_pre_saved_traj:
        RRT = RRT_star(x_start, 1500, obstacles, 1)
        path_exists = RRT.find_path(x_goal, map_boundary)
    else:
        path_exists = True
    #########################################################################

    current_state = env.reset(position=x_start)

    # If a path has been found, proceed to follow it
    if not path_exists:
        print("No path was found for the given number of iterations")
    else:
        print("Path found, applying smoothing.")

        if not use_pre_saved_traj:
            # Apply the path interpolation algorithm selected, the path is simplified to make if time-feasible
            path_list = RRT.get_straight_path()
            if min_snap:
                # Parameters can be adjusted as necessary
                pos, vel, acc, jerk, snap, ts = min_snap_optimizer_3d(path_list, penalty=penalty, time_optimal=False,
                                                    act_const=False, check_collision=False, obstacles=None, total_time=traj_total_time)
            else:
                pos, vel, acc = cubic_spline(path_list, T=traj_total_time)
            # save the trajectory
            # np.savez('traj.npz', pos=pos, vel=vel, path_list=path_list)

        else:
            # load the pre-saved trajectory
            traj = np.load('traj.npz')
            path_list = traj['path_list']
            pos = traj['pos']
            vel = traj['vel']

        print("Smoothing completed, tracking trajectory")

        if dynamic_obstacle:
            obstacle_traj = np.flipud(pos)  # reverse the trajectory as obstacle trajectory

        # Plot the initial point (may don't need it)
        ax1.plot(pos[:, 0], pos[:, 1], pos[:, 2], c='g', linewidth=2)
        real_trajectory = np.zeros((1, 3))
        real_orientation = np.zeros((1, 4))

        if not waypoint_navigation:
            # follow the path in segments
            for i in range(len(pos) - policy.model.N):

                if dynamic_obstacle:
                    # dynamic obstacle
                    pos_obstacle = obstacle_traj[i]
                    print("obstacle position: ", pos_obstacle)
                elif obstacle and not dynamic_obstacle:
                    # static obstacle
                    show_up_time = int(0.5 * len(pos))
                    pos_obstacle = pos[show_up_time]
                else:
                    pass

                if obstacle:
                    # if the agent is close to the obstacle, then avoid it
                    if np.sum((current_state['x'] - pos_obstacle)**2) <= 2.5:
                        state_des = np.hstack((pos[i + 4*policy.model.N], vel[i + 4*policy.model.N], pos_obstacle))
                        print("avoiding obstacle......")
                    else:
                        state_des = np.hstack((pos[i + policy.model.N], vel[i + policy.model.N], np.array([100, 100, 100])))
                else:
                    state_des = np.hstack((pos[i + policy.model.N], vel[i + policy.model.N]))

                closest_obstacle = find_closest(current_state, obstacles)
                bbox_size = closest_obstacle / np.sqrt(3)
                print("closest obstacle: ", bbox_size)
                if collision_avoidance_guarantee:
                    action = policy.control(current_state, state_des, bounding_box_size=bbox_size)
                else:
                    action = policy.control(current_state, state_des, bounding_box_size=50)
                cmd_rotor_speeds = action['cmd_rotor_speeds']
                obs, reward, done, info = env.step(cmd_rotor_speeds)
                print("current:", obs['x'])
                print('des_position: ', state_des[:3])
                if i == 0:
                    real_trajectory = np.reshape(obs['x'], (1, 3))
                    real_orientation = np.reshape(obs['q'], (1, 4))
                else:
                    real_trajectory = np.vstack((real_trajectory, np.reshape(obs['x'], (1, 3))))
                    real_orientation = np.vstack((real_orientation, np.reshape(obs['q'], (1, 4))))
                current_state = obs
                t += time_step
                total_SE += (np.sum((obs['x'] - state_des[:3]) ** 2) * time_step)
                total_energy += (np.sum(cmd_rotor_speeds ** 2) * time_step)
                # if current position is very close to the goal point, terminate the loop
                if np.sqrt(np.sum((obs['x'] - pos[-1]) ** 2)) <= 0.5:
                    break

        else: # use waypoint navigation, no velocity information, only waypoints given by RRT*

            waypoints = path_list
            i = 0

            while(True):
                if dynamic_obstacle:
                    # dynamic obstacle
                    pos_obstacle = obstacle_traj[i]
                    print("obstacle position: ", pos_obstacle)
                elif obstacle and not dynamic_obstacle:
                    # static obstacle
                    show_up_time = int(0.5 * len(pos))
                    pos_obstacle = pos[show_up_time]
                    print("obstacle position: ", pos_obstacle)
                else:
                    pass

                if obstacle:
                    # if the agent is close to the obstacle, then avoid it
                    if np.sum((current_state['x'] - pos_obstacle)**2) <= 2.5:
                        state_des = np.hstack((waypoints[i], np.zeros(3), pos_obstacle))
                        print("avoiding obstacle......")
                    else:
                        state_des = np.hstack((waypoints[i], np.zeros(3), np.array([100, 100, 100])))
                else:
                    state_des = np.hstack((waypoints[i], np.zeros(3)))

                closest_obstacle = find_closest(current_state, obstacles)
                bbox_size = closest_obstacle / np.sqrt(3)
                print("closest obstacle: ", bbox_size)

                if collision_avoidance_guarantee:
                    action = policy.control(current_state, state_des, bounding_box_size=bbox_size)
                else:
                    action = policy.control(current_state, state_des, bounding_box_size=50)

                cmd_rotor_speeds = action['cmd_rotor_speeds']
                obs, reward, done, info = env.step(cmd_rotor_speeds)
                print("current:", obs['x'])
                print('des_position: ', state_des[:3])
                if i == 0:
                    real_trajectory = np.reshape(obs['x'], (1, 3))
                    real_orientation = np.reshape(obs['q'], (1, 4))
                else:
                    real_trajectory = np.vstack((real_trajectory, np.reshape(obs['x'], (1, 3))))
                    real_orientation = np.vstack((real_orientation, np.reshape(obs['q'], (1, 4))))
                current_state = obs
                t += time_step
                total_SE += (np.sum((obs['x'] - state_des[:3]) ** 2) * time_step)
                total_energy += (np.sum(cmd_rotor_speeds ** 2) * time_step)
                # if current position is close to the current waypoint, give it the next one
                if np.sqrt(np.sum((obs['x'] - waypoints[i]) ** 2)) <= 0.3 and i < len(waypoints)-1:
                    i += 1
                # if current position is very close to the goal point, terminate the loop
                if np.sqrt(np.sum((obs['x'] - waypoints[-1]) ** 2)) <= 0.05 and i == len(waypoints)-1:
                    break
                elif t >= 120:
                    break

        # Print the final metrics of the simulation
        print("Sum of tracking error (integration): ", total_SE)
        print("Total time: ", t)
        print("Sum of energy consumption (integration)", total_energy)

        if obstacle:
            ax1.plot(pos_obstacle[0], pos_obstacle[1], pos_obstacle[2], marker='o', c='y', markersize=16)
        if dynamic_obstacle:
            plot_all(fig, ax1, obstacles, x_start, x_goal, path_list, real_trajectory, real_orientation, dynamic=True, obstacle_trajectory=obstacle_traj)
        else:
            plot_all(fig, ax1, obstacles, x_start, x_goal, path_list, real_trajectory, real_orientation)

